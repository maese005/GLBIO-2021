{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQlw2vixAmdo"
      },
      "source": [
        "## **About this Script**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHrgNFmnArOx"
      },
      "source": [
        "This script generates logistic regression model from scratch, in python, for a diabetes dataset.\n",
        "\n",
        "This dataset describes the medical records for over 700 female Pima native Americans with 8 characteristics. These covariates include:\n",
        "*   preg = Number of times pregnant\n",
        "*   plas = Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "*   pres = Diastolic blood pressure (mm Hg)\n",
        "*   skin = Triceps skin fold thickness (mm)\n",
        "*   test = 2-Hour serum insulin (mu U/ml)\n",
        "*   mass = Body mass index (weight in kg/(height in m)^2)\n",
        "*   pedi = Diabetes pedigree function\n",
        "*   age = Age (years)\n",
        "The outcome variable is yes/1/diabetes or no/0/no diabetes\n",
        "\n",
        "If you have questions, please contact: maese005@umn.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUhuBwjuAwVd"
      },
      "source": [
        "## **Step 1:** Get Data and load libraries\n",
        "\n",
        "Here is the link to the github which stores the data: https://github.com/maese005/GLBIO-2021\n",
        "\n",
        "The data was originally obtained from Kaggle: https://www.kaggle.com/kumargh/pimaindiansdiabetescsv\n",
        "\n",
        "This dataset is also packaged in R: https://www.rdocumentation.org/packages/pdp/versions/0.7.0/topics/pima\n",
        "\n",
        "Please download this file into your Google Drive. From there, we will mount Google Collab to Google Drive to access the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzhWTFianaty",
        "outputId": "60a8eae0-606e-4b42-d92b-55c179fbde1e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqCAK5DrBiCs"
      },
      "source": [
        "import numpy as np \n",
        "import statistics\n",
        "import csv\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJ1NsWr57R83"
      },
      "source": [
        "#Read the data as a .csv and view. \n",
        "with open('/content/drive/My Drive/AI_Workshop/Code and Exercises/pima-indians-diabetes.csv', 'r') as file:\n",
        "    reader = csv.reader(file)\n",
        "    for row in reader:\n",
        "        print(row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "IAOXLAq-8bf1",
        "outputId": "a5f3533b-8bb6-4d7f-9c65-19e2992f9386"
      },
      "source": [
        "#You can also read the .csv file using pandas. \n",
        "result = pd.read_csv('/content/drive/My Drive/AI_Workshop/Code and Exercises/pima-indians-diabetes.csv', header=None) #header=None so that you don't read the first row as column names.\n",
        "result.shape #768 people and 8 features with 1 output.\n",
        "result.head() #Take a look at the data (only works on pandas dataframe, not numpy)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6</td>\n",
              "      <td>148</td>\n",
              "      <td>72</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "      <td>33.6</td>\n",
              "      <td>0.627</td>\n",
              "      <td>50</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>85</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>0</td>\n",
              "      <td>26.6</td>\n",
              "      <td>0.351</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>8</td>\n",
              "      <td>183</td>\n",
              "      <td>64</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>23.3</td>\n",
              "      <td>0.672</td>\n",
              "      <td>32</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>89</td>\n",
              "      <td>66</td>\n",
              "      <td>23</td>\n",
              "      <td>94</td>\n",
              "      <td>28.1</td>\n",
              "      <td>0.167</td>\n",
              "      <td>21</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>137</td>\n",
              "      <td>40</td>\n",
              "      <td>35</td>\n",
              "      <td>168</td>\n",
              "      <td>43.1</td>\n",
              "      <td>2.288</td>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0    1   2   3    4     5      6   7  8\n",
              "0  6  148  72  35    0  33.6  0.627  50  1\n",
              "1  1   85  66  29    0  26.6  0.351  31  0\n",
              "2  8  183  64   0    0  23.3  0.672  32  1\n",
              "3  1   89  66  23   94  28.1  0.167  21  0\n",
              "4  0  137  40  35  168  43.1  2.288  33  1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPVVo70Y_Zzn"
      },
      "source": [
        "result = result.to_numpy() #In order to index, you must convert pandas data frame to numpy. "
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlJfAacSBD9a"
      },
      "source": [
        "## **Step 2:** Prepare the input (X) and output (y) data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ1_tr2-_muB",
        "outputId": "191ed482-b896-416d-8f3d-cf427559177f"
      },
      "source": [
        "X = result[:,0:8]\n",
        "X.shape #768 8\n",
        "X"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60yb5cGK_5GG"
      },
      "source": [
        "y = np.round(result[:,8])\n",
        "y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwN156z0DX2I"
      },
      "source": [
        "## **Step 3:** Define our logistic regression function and cross validation function from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36GiTbrqmnvf"
      },
      "source": [
        "#Define class(MyLogisticReg2).\n",
        "\n",
        "class MyLogisticReg2:\n",
        "    \n",
        "    #Initializes the parameters w and w0. \n",
        "    def __init__(self, d, lr, n_iters):  \n",
        "        #Store these values.\n",
        "        #d is the number of dimensions/features. \n",
        "        self.d=d #For boston, d=13. \n",
        "        self.lr=lr\n",
        "        self.n_iters=n_iters\n",
        "        \n",
        "        #Create some weights. Set them to none at first.\n",
        "        #Create the bias. Set it to none. \n",
        "        #We will have to come up with them.\n",
        "        self.weights=None\n",
        "        self.bias=None\n",
        "    \n",
        "    #Develop a fit method. \n",
        "    #This is the training step and involves gradient descent.\n",
        "    #x is a numpy vector of size m*n where m is the number of samples and n is the number of features for each sample.\n",
        "    #y is also of size m. Each training sample has 1 vector.\n",
        "    def fit(self, X, y):\n",
        "        #We need to initialize the weights/our parameters. \n",
        "        #Initialize the parameters.\n",
        "        n_samples, n_features = X.shape\n",
        "\n",
        "        #Initialize the weights by creating a vector of only 0's. It's size is the number of features.\n",
        "        self.weights = np.zeros(n_features)\n",
        "        #Set the bias to 0 at first.\n",
        "        #Note: you can also use random numbers for the initialization, but 0 is just fine.\n",
        "        self.bias=0\n",
        "        \n",
        "        #Use gradient descent. Iteratively update the weights.\n",
        "        for _ in range(self.n_iters): #n_iters is the number of iterations we want to have.\n",
        "            linear_model = np.dot(X, self.weights) + self.bias #This is wx+b. Use np.dot to multiple the vectors. \n",
        "            #Then apply the sigmoid function. Apply a helper method below.\n",
        "            y_predicted = self.sigmoid(linear_model) #This is our approximation of y.\n",
        "            #Update our weights using the update rules.\n",
        "            \n",
        "            #This is the derivative with respect to w.\n",
        "            dw=(1/n_samples) * np.dot(X.T, (y_predicted-y)) #y predicted minus the actual y.\n",
        "            \n",
        "            #The derivative with respect to bias is the same but without the x. \n",
        "            db=(1/n_samples)*np.sum(y_predicted-y)\n",
        "            \n",
        "            #Now that we have our derivatives, update the parameters.\n",
        "            self.weights-=self.lr * dw\n",
        "            self.bias-=self.lr * db\n",
        "        #set_trace() \n",
        "        \n",
        "    #Develop a predict method. Input the new test samples that you want to predict. \n",
        "    def predict(self, X):\n",
        "        #First, approximate the data using a linear model.\n",
        "        linear_model=np.dot(X, self.weights) + self.bias\n",
        "        #Then apply a sigmoid function to gete th probability.\n",
        "        y_predicted=self.sigmoid(linear_model)\n",
        "        #Predict the y class. Use a list comprehension. \n",
        "        y_predicted_cls=[1 if i > 0.5 else 0 for i in y_predicted] #Do this for each value in y_predicted.\n",
        "        return y_predicted_cls\n",
        "    \n",
        "    def sigmoid(self, linear_model):\n",
        "        return 1/(1+np.exp(-linear_model))\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMVL2FsyztQT"
      },
      "source": [
        "Store the logistic regression function we just created in a variable (model) so that we can reference it in our k fold cross validation function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRdGHvjxobT9"
      },
      "source": [
        "model=MyLogisticReg2(d=2, lr=0.01, n_iters=1000)\n",
        "#model.fit(xtrain, ytrain)\n",
        "#model.predict(xtest)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UquV3AjoYqZ"
      },
      "source": [
        "#Create k fold cross validation function.\n",
        "#This function performs k fold cross validation on X and y using method and returns the error rate in each fold.\n",
        "#The method used is my logistric regression function.\n",
        "\n",
        "def my_cross_val(X, y, k, model):\n",
        "    from sklearn.metrics import accuracy_score\n",
        "    error_rate=[0 for x in range(k)] #Or error_rate=np.zeros(10)\n",
        "    for i in range(k):\n",
        "        random_array=np.random.rand(X.shape[0])\n",
        "        split=random_array<np.percentile(random_array,70)\n",
        "        data_train3=X[split]\n",
        "        target_train3=y[split]\n",
        "        data_test3=X[~split]\n",
        "        target_test3=y[~split]\n",
        "        \n",
        "        BOSTON.fit(data_train3, target_train3)\n",
        "        #set_trace()\n",
        "        y_prediction=BOSTON.predict(data_test3)\n",
        "        #set_trace()\n",
        "        error_rate[i]=(1-accuracy_score(target_test3, y_prediction)) #Output is the error.\n",
        "    return (error_rate, np.mean(error_rate), statistics.stdev(error_rate))\n",
        "    #Will report the error rates across folds, mean across the error rates, standard deviation."
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg-IEje7ETX3"
      },
      "source": [
        "## **Step 4:** Compare performance to sklearns logistic regression model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SeOSnm71KM5",
        "outputId": "370e1ede-f818-444d-fcaf-4b0eb898e309"
      },
      "source": [
        " #Apply the cross validation code to the datasets...accuracy is approximately 70%\n",
        " my_cross_val(X, y, 5, model)"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.35064935064935066,\n",
              "  0.33333333333333337,\n",
              "  0.5974025974025974,\n",
              "  0.4025974025974026,\n",
              "  0.2943722943722944],\n",
              " 0.39567099567099573,\n",
              " 0.11928744045486377)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3kSwwUIoTpE",
        "outputId": "bfc341bd-6f97-49ea-ebd6-ddf430523b6b"
      },
      "source": [
        "#Prepare sklearn's default logistic regression model.\n",
        "#I am going to compare the imputations from this model with those calculated using my LR model.\n",
        "\n",
        "myLR=LogisticRegression(penalty='l2',solver='lbfgs', multi_class='multinomial', max_iter=5000)\n",
        "\n",
        "my_cross_val(X, y, 5, myLR)\n",
        "#We can see that our model performs slightly better / almost equal to sklearns. "
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.37229437229437234,\n",
              "  0.6277056277056277,\n",
              "  0.4372294372294372,\n",
              "  0.4372294372294372,\n",
              "  0.316017316017316],\n",
              " 0.43809523809523804,\n",
              " 0.1174588992685196)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    }
  ]
}