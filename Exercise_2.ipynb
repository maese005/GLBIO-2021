{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Example 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owOhmTWYtGu0"
      },
      "source": [
        "## **About this Script**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dP_s0WjNnh0a"
      },
      "source": [
        "This script creates a convolutional neural network (CNN) for DNA sequence classification. \n",
        "\n",
        "Specifically, it classifies promoter sequences into positive (+) or negative (-) classes. This type of classification can have a variety of applications. For instance, researchers may classify sequences containing regions that wrap around histones as positive and sequences that don't as negative. Such classification would enable prediction of histone profiles from sequences and aid in understanding gene expression patterns. Here is an example of a paper that applied a CNN for such classification: https://www.scirp.org/journal/paperinformation.aspx?paperid=65923\n",
        "\n",
        "**A promoter**: a DNA sequence that turns a gene on or off. \n",
        "\n",
        "This script was adapted and modified from https://github.com/ahsanazim/cnn\n",
        "If you have any questions, please contact: maese005@umn.edu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Otw32uTFtnM8"
      },
      "source": [
        "## **Step 1:** Get Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wN9odO2lox2E"
      },
      "source": [
        "First, mount your Google Drive to your Google Colab.\n",
        "\n",
        "This will allow you to share files and access images stored in Google Drive from Google Collab.\n",
        "\n",
        "Once you run this code, you will receive a prompt asking you to click a link. When you click on this link, it will allow for 'Google Files Stream' to access your drive.\n",
        "\n",
        "After, you will receive a long authentication code which you need to copy and enter into your Colab's notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCkvAfeuolm5",
        "outputId": "e50ca449-def6-4591-c784-eaf1bd4309cf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOQx-mzv4kgR"
      },
      "source": [
        "Now that your Google Collab is mounted to your Google Drive, you must obtain the data for this script.\n",
        "\n",
        "The data can be obtained at this link: https://drive.google.com/file/d/1xsRPoHSNQv5r9gK5uwVfVmY_qjBtRaIj/view?usp=sharing\n",
        "\n",
        "To access the data from your Google Drive, click on the link. Save the data to your Google Drive. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng9R7qOmt2do"
      },
      "source": [
        "## **Step 2:** Import python libraries and define functions that will ease development of our CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFRvNWcrrTUw"
      },
      "source": [
        "def conv_labels(labels, dataset='splice'):\n",
        "    converted = []\n",
        "    for label in labels:\n",
        "        if dataset == 'splice':\n",
        "            if label == 'EI':\n",
        "                converted.append(0)\n",
        "            elif label == 'IE':\n",
        "                converted.append(1)\n",
        "            elif label == 'N':\n",
        "                converted.append(2)\n",
        "        elif dataset == 'promoter':\n",
        "            if label =='+':\n",
        "                converted.append(0)\n",
        "            elif label == '-':\n",
        "                converted.append(1)\n",
        "    return converted\n",
        "\n",
        "def create_dict(nucleotides):\n",
        "    vec_dict = {}\n",
        "    perms = k_len_perms(nucleotides, 3)\n",
        "    perms.sort()\n",
        "    for idx, seq in enumerate(perms):\n",
        "        hot_vec = [ 0 for i in range(0, len(perms))]\n",
        "        hot_vec[idx] = 1\n",
        "        vec_dict[seq] = hot_vec\n",
        "    return vec_dict\n",
        "\n",
        "def k_len_perms(letters, k):\n",
        "    n = len(letters)\n",
        "    perms = []\n",
        "    k_len_perms_hlpr(perms, letters, \"\", n, k)\n",
        "    return perms\n",
        "\n",
        "def k_len_perms_hlpr(perms, letters, prefix, n, k):\n",
        "    if (k == 0):\n",
        "        perms.append(prefix)\n",
        "        return\n",
        "    for i in range(0, n):\n",
        "        newPrefix = prefix + letters[i]\n",
        "        k_len_perms_hlpr(perms, letters, newPrefix, n, k - 1)\n",
        "\n",
        "def get_rep_mat(seq, hot_vec_dict, k=3, r_size=2):\n",
        "    words = word_seq(seq, k)\n",
        "    rep_mat = create_rep_mat(words, hot_vec_dict, r_size)\n",
        "    return rep_mat\n",
        "\n",
        "def word_seq(seq, k, stride=1):\n",
        "    i = 0\n",
        "    words = []\n",
        "    while i <= len(seq) - k:\n",
        "        words.append(seq[i: i + k])\n",
        "        i += stride\n",
        "    return words\n",
        "\n",
        "def create_rep_mat(words, hot_vec_dict, r_size):\n",
        "    mat_len = len(words) - r_size + 1\n",
        "    mat = [[] for i in range(0, mat_len)]\n",
        "    i = 0\n",
        "    while i < mat_len:\n",
        "        j = i\n",
        "        while j < i + r_size:\n",
        "            mat[i].append(hot_vec_dict[words[j]])\n",
        "            j += 1\n",
        "        i += 1\n",
        "    return mat\n",
        "\n",
        "def get_rep_mats(seqs):\n",
        "    rep_mats = []\n",
        "    hot_vec_dict = create_dict('ACGT')\n",
        "    for seq in seqs:\n",
        "        rep_mat = get_rep_mat(seq, hot_vec_dict, k=3, r_size=1)\n",
        "        rep_mats.append(rep_mat)\n",
        "    return rep_mats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lw-rZzFu1dn"
      },
      "source": [
        "We will be using **Keras** to build our CNN.\n",
        "\n",
        "**Keras** is a deep learning Python API of TensorFlow (which is a platform used to solve machine learning problems). The core data structures of Keras are layers and models. The simplest model is the **Sequential model**, which can be described as a linear stack of layers. \n",
        "\n",
        "Additional information about Keras here: https://keras.io/about/#:~:text=Keras%20is%20a%20deep%20learning,key%20to%20doing%20good%20research."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oEjJo8MpQ2S"
      },
      "source": [
        "#numpy is helpful when we want to work with numbers and numerical operations. \n",
        "import numpy as np\n",
        "\n",
        "np.random.seed(123)  #Whenever you build a model, always set the seed for reproducibility purposes. \n",
        "\n",
        "#We will be using Keras to build our CNN. \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Convolution2D, MaxPooling2D #These are the layers we will be using in our model. \n",
        "from keras.utils import np_utils\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7-0exWnwJN-"
      },
      "source": [
        "## **Step 3:** Prepare training and testing data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9yZ7aLuupGb"
      },
      "source": [
        "Read the promoter sequence data text file into Python. \n",
        "\n",
        "First, we will use the open() function, which will open the text file for reading. \n",
        "\n",
        "Second, we will read text from the file. \n",
        "\n",
        "Lastly, we will close the file using the file close() method. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1jGwdmvwaeg"
      },
      "source": [
        "f=open(\"/content/drive/My Drive/AI_Workshop/Code and Exercises/promoters.data.txt\")\n",
        "\n",
        "seqs = []\n",
        "labels = []\n",
        "for line in f: #This for loop will fill the seqs and labels list. \n",
        "  line_no_wspace = line.replace(\" \",\"\")\n",
        "  line_no_nwline = line_no_wspace.replace(\"\\n\",\"\")\n",
        "  line_arr = line_no_nwline.split(\",\")\n",
        "  label = line_arr[0]\n",
        "  seq = line_arr[2]\n",
        "  \n",
        "  #Sequence cleaning\n",
        "  seq = seq.upper()    \n",
        "  seq = seq.replace(\"\\t\",\"\")      \n",
        "  seq = seq.replace(\"N\",\"A\")  \n",
        "  seq = seq.replace(\"D\",\"G\")\n",
        "  seq = seq.replace(\"S\",\"C\")\n",
        "  seq = seq.replace(\"R\",\"G\")\n",
        "\n",
        "  labels.append(label)\n",
        "  seqs.append(seq)\n",
        "\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY97phO3yhN0"
      },
      "source": [
        "seqs #Print the sequences stored in this file. It's always a good idea to take a look at our data!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BTgZumnyndR"
      },
      "source": [
        "labels #Print the labels for each sequence. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSzk0OrpREnh"
      },
      "source": [
        "Explore the sequence data.\n",
        "*   What data structure is it? (It's a list).\n",
        "*   What are the dimensions? (Its length is 106, so it contains 106 sequences).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XZKsVP0uLZzW",
        "outputId": "cc1f8ea7-04e4-470c-f5c8-4c754ba518e1"
      },
      "source": [
        "type(seqs) #list\n",
        "len(seqs) #106 sequences. \n",
        "seqs[0] #Lets take a look at the first sequence in our sequence list, which is located at index 0. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TACTAGCAATACGCTTGCGTTCGGTGGTTAAGTATGTATAATGCGCGGGCTTGTCGT'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tirjcoDNRd_W"
      },
      "source": [
        "Convert the sequence data into an array of representation matrices using the function defined above **get_rep_mats** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHAGzwdg5cGr"
      },
      "source": [
        "X=get_rep_mats(seqs) \n",
        "\n",
        "y=labels #Set the labels as y. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bea7LK6bR2Oz"
      },
      "source": [
        "Explore the sequence data now that it has been converted from letters (images of nucleotides) to numbers. \n",
        "*   What data structure is it? (It's still a list).\n",
        "*   What are the dimensions? (Its length is still 106 because it contains 106 sequences as before). \n",
        "*   What did the get_rep_mats function do? (It converted each letter, in each sequence, to a vector of 1's and 0's). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RazrijhZOtj1",
        "outputId": "fddb7df8-a9c7-4a34-c03e-576eec5627bd"
      },
      "source": [
        "type(X) #list\n",
        "len(X) #106\n",
        "len(X[0]) #55...55 sets of 1's and 0's. Each set represents a letter in sequence 1. \n",
        "len(X[0][0]) #1...a vector of a bunch of 1's and 0's that represent the first letter in the first sequence."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 276
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwV0bnkhxPdG"
      },
      "source": [
        "Split data into training and testing data.\n",
        "\n",
        "The training data will have 90 images, the testing will have 16 (recall there are 106 total). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnxGePXw0_5Q"
      },
      "source": [
        "for i in X:\n",
        "    for idx, j in enumerate(i):\n",
        "        i[idx] = j[0]\n",
        "\n",
        "y = conv_labels(y, \"promoter\") #Convert to integer labels\n",
        "X = np.asarray(X) #Work with np arrays\n",
        "y = np.asarray(y)\n",
        "X_train = X[0:90]\n",
        "X_test = X[90:]\n",
        "y_train = y[0:90]\n",
        "y_test = y[90:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciEXgrZtVwYD",
        "outputId": "d27deb38-d7a0-468f-f888-d3cce95f3d68"
      },
      "source": [
        "X_train.shape #90, 55, 64"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 55, 64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaEUm0ShWNNs",
        "outputId": "ea34c154-9969-4611-b838-9f71e238a415"
      },
      "source": [
        "y_train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 279
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ykcNg2SxmQ3"
      },
      "source": [
        "## **Step 4:** Preprocess the data into forms that will work for the CNN. \n",
        "\n",
        "Here, it's very important that we are aware of our dimensions. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5vRNrzyBF6i"
      },
      "source": [
        "#Preprocess input data\n",
        "X_train = X_train.reshape(X_train.shape[0], 55, 64, 1)  # (90, 55, 64) --> (90, 55, 64, 1)...reshape the data by adding 4th dimensions. 55 image rows, 65 image columns. \n",
        "X_test = X_test.reshape(X_test.shape[0], 55, 64, 1)\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "#Convert 1-dimensional class arrays to 3-dimensional class matrices.\n",
        "Y_train = np_utils.to_categorical(y_train, 2)\n",
        "Y_test = np_utils.to_categorical(y_test, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z45Dfbx-V8b3",
        "outputId": "3f321b34-99d5-4a89-f06b-b2662f2b6563"
      },
      "source": [
        "X_train.shape #90, 55, 64, 1 because we have 90 images of 55 by 64 pixels not in RGM (3 color channels). We are using grayscale, so the color channel is 1. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 55, 64, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9bGtBzmBqXy",
        "outputId": "b1a7ab26-f537-41b7-b621-e47d8d5e2243"
      },
      "source": [
        "len(X_train) #90 training DNA sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Szz-qJHfB6Ak",
        "outputId": "a2388d6b-ccff-4fa6-a1a0-871562773c5d"
      },
      "source": [
        "len(y_train) #90 training labels for DNA sequences"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "90"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 283
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5h-Z1PWVB-_6",
        "outputId": "cc0ef2ab-93b5-4770-ef1b-1acf36179723"
      },
      "source": [
        "y_train #We have a binary label of 1's and 0s'. "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTY8X1H2x9aa"
      },
      "source": [
        "## **Step 5:** Build the neural network by adding multiple layers. \n",
        "\n",
        "We will do this by creating a sequential model and adding the layers. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vTUF3Rpcv_x"
      },
      "source": [
        "**What is an input shape tensor?**\n",
        "\n",
        "**Tensors**: matrices with shapes that flow between layers. \n",
        "\n",
        "In Keras, the input layer itself is not a layer, it is a tensor. It's the starting tensor that you send to the first hidden layer. This tensor must have the same shape as your training data. \n",
        "\n",
        "Ex: if you have 90 images of 55 x 64 pixels in RGB (3 color channels), the shape of your input data is (90, 55, 64, 3). Therefore, when you use **input_shape** in keras, you must use this shape. We will use 55, 64, 1 because we are in the grayscale\n",
        "\n",
        "Your input shape is the only shape you have to define or provide in your model because your model can't know it...only you know it based on your training data. All other shapes are calculated automatically based on the units and particularities of each layer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bs6NrvJkzVDv"
      },
      "source": [
        "**What is a convolution?**\n",
        "\n",
        "A convolution/weight matrix/convolution matrix/kernel/filter is a small matrix of weights with the same number of rows as there are columns. \n",
        "\n",
        "A 3x3 convolution filter is generally used when you apply 2D convolutions on images. There's always a third dimension, but you don't have to include it; it is included automatically. This third dimension indicates the number of channels of the input image. Ex: a gray scale image requires 3x3x1...RGB image requires 3x3x3. **A convolution filter is referred to by its first 2 dimensions**\n",
        "\n",
        "More information here: https://medium.com/@icecreamlabs/3x3-convolution-filters-a-popular-choice-75ab1c8b4da8#:~:text=It%20is%20used%20for%20blurring,a%20kernel%20and%20an%20image.&text=While%20applying%202D%20convolutions%20like,a%20third%20dimension%20in%20size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_shZKS9ZQAN"
      },
      "source": [
        "model = Sequential() #Initiate the sequential model. \n",
        "\n",
        "#Apply a 3x3 convolution with 64 output filters on a 55 x 64 image in the grayscale. \n",
        "#Note: when using this as the first layer in a model, provide the keyword argument input_shape (Ex: input_shape=(130, 130, 3) for 130x130 RGB images). \n",
        "model.add(Convolution2D(64, 3, 3, activation='relu', input_shape=(55, 64, 1))) \n",
        "#input_shape must contain 3 dimensions. Internally, Keras will add the batch dimensions, making it 4 dimensions total. \n",
        "#The 1 indicates the channel. It lets Keras know that you are working on a grayscale image (because it is 1). \n",
        "\n",
        "model.add(Convolution2D(64, 3, 3, activation='relu')) \n",
        "#The kernel_size argument (3,3) represents height, width of the kernel. Kernel depth will be the same as the depth of the image..\n",
        "#64 is the filter parameter in Keras's Convolution2D function.\n",
        "#There is no good answer for the question, how do you determine the value of this filter parameter?\n",
        "#You would have to carefully design and fine tune your model through many experiments. \n",
        "#However, there are some guidelines as to how to choose the number of filters. \n",
        "#https://stackoverflow.com/questions/48243360/how-to-determine-the-filter-parameter-in-the-keras-conv2d-function\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(2, activation='softmax'))   # since 2 classes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K20Com6UC8FC"
      },
      "source": [
        "Compile the model. \n",
        "\n",
        "You must compile the model before you can train or evaluate it. \n",
        "\n",
        "Here, the efficient **ADAM optimization** algorithm is used. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VHNl_w3CvWt"
      },
      "source": [
        "model.compile(optimizer='adam', \n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "#Here, the loss function chosen is sparse_categorical_crossentropy. \n",
        "#This loss function is generally recommended when you have a 1D integer encoded target."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiaTwUtG2BNU"
      },
      "source": [
        "Fit the model. \n",
        "\n",
        "Call fit() to train the model by slicing the data into batches of size batch_size and repeatedly iterating over the entire dataset for the number of epochs specified. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjUl1qeK-Wfr",
        "outputId": "fa40f225-e685-4232-b0d2-eb8817eb6313"
      },
      "source": [
        "model.fit(x=X_train,\n",
        "          y=Y_train,\n",
        "          validation_data=(X_test, Y_test), \n",
        "          batch_size=32,\n",
        "          epochs=20,\n",
        "          verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3/3 [==============================] - 1s 117ms/step - loss: 0.6895 - accuracy: 0.5891 - val_loss: 0.7429 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6752 - accuracy: 0.6047 - val_loss: 0.8248 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.6538 - accuracy: 0.5952 - val_loss: 0.9039 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.6545 - accuracy: 0.5835 - val_loss: 0.9346 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.6399 - accuracy: 0.5874 - val_loss: 0.9122 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.6305 - accuracy: 0.5601 - val_loss: 0.8763 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.5920 - accuracy: 0.6403 - val_loss: 0.8741 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.5782 - accuracy: 0.6576 - val_loss: 0.8733 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.5415 - accuracy: 0.7556 - val_loss: 0.8924 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.4972 - accuracy: 0.8095 - val_loss: 0.8751 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.4481 - accuracy: 0.8764 - val_loss: 0.8654 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.4530 - accuracy: 0.9332 - val_loss: 0.8754 - val_accuracy: 0.0625\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.3691 - accuracy: 0.9198 - val_loss: 0.8624 - val_accuracy: 0.0625\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.2844 - accuracy: 0.9677 - val_loss: 0.8016 - val_accuracy: 0.3750\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.2438 - accuracy: 0.9889 - val_loss: 0.8895 - val_accuracy: 0.3125\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.1793 - accuracy: 0.9889 - val_loss: 0.8759 - val_accuracy: 0.3750\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.1527 - accuracy: 1.0000 - val_loss: 0.6906 - val_accuracy: 0.6875\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.1287 - accuracy: 0.9827 - val_loss: 0.8482 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 1.1467 - val_accuracy: 0.2500\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.0873 - accuracy: 1.0000 - val_loss: 0.9266 - val_accuracy: 0.4375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f70918b3dd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 293
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crgayfjaCxBS",
        "outputId": "396a1fe6-d201-4341-fec2-8125661aa69b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_45 (Conv2D)           (None, 18, 21, 64)        640       \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 6, 7, 64)          36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_26 (Dropout)         (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_18 (Flatten)         (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dropout_27 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 111,682\n",
            "Trainable params: 111,682\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DYFck_dDS6l"
      },
      "source": [
        "Estimate the performance of the model on unseen data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiFd-RvTDOwG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f77e6de-ed3c-4dc9-cb22-82bef356219d"
      },
      "source": [
        "model.evaluate(X_test, Y_test, verbose=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9265512228012085, 0.4375]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 296
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkgZlkzLxSvn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1160fcea-a8cc-49bf-a7bf-bc1c7574e8bb"
      },
      "source": [
        "history=model.fit(X_train, Y_train, batch_size=32, epochs=20, validation_data=(X_test, Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.0471 - accuracy: 1.0000 - val_loss: 0.8365 - val_accuracy: 0.5625\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.9376 - val_accuracy: 0.5000\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0291 - accuracy: 1.0000 - val_loss: 1.1854 - val_accuracy: 0.4375\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.2927 - val_accuracy: 0.3750\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0214 - accuracy: 1.0000 - val_loss: 1.0377 - val_accuracy: 0.4375\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 0.8378 - val_accuracy: 0.6875\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.8975 - val_accuracy: 0.6250\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.0456 - val_accuracy: 0.5000\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.2896 - val_accuracy: 0.4375\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.4594 - val_accuracy: 0.4375\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.4583 - val_accuracy: 0.4375\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.3170 - val_accuracy: 0.4375\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.1604 - val_accuracy: 0.5000\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.0620 - val_accuracy: 0.5625\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.0486 - val_accuracy: 0.5625\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.0488 - val_accuracy: 0.5625\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.0491 - val_accuracy: 0.6250\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.1240 - val_accuracy: 0.5000\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.1809 - val_accuracy: 0.5000\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.2256 - val_accuracy: 0.5000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2-cBufOyShc"
      },
      "source": [
        "The returned history object contains a record of the loss values and metric values acquired during training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQ0vqVcLyQbV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c90f30b5-c3e9-4f15-a7f5-0fd70ab69b01"
      },
      "source": [
        "history.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': [1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0,\n",
              "  1.0],\n",
              " 'loss': [0.04711845889687538,\n",
              "  0.03484797105193138,\n",
              "  0.029053818434476852,\n",
              "  0.017926031723618507,\n",
              "  0.021369624882936478,\n",
              "  0.01657998003065586,\n",
              "  0.014896935783326626,\n",
              "  0.009546159766614437,\n",
              "  0.009708361700177193,\n",
              "  0.006332335993647575,\n",
              "  0.00859782937914133,\n",
              "  0.006212372332811356,\n",
              "  0.004263704176992178,\n",
              "  0.0024531022645533085,\n",
              "  0.00557808019220829,\n",
              "  0.003262109821662307,\n",
              "  0.002391067799180746,\n",
              "  0.004019764252007008,\n",
              "  0.0019499287009239197,\n",
              "  0.0016564119141548872],\n",
              " 'val_accuracy': [0.5625,\n",
              "  0.5,\n",
              "  0.4375,\n",
              "  0.375,\n",
              "  0.4375,\n",
              "  0.6875,\n",
              "  0.625,\n",
              "  0.5,\n",
              "  0.4375,\n",
              "  0.4375,\n",
              "  0.4375,\n",
              "  0.4375,\n",
              "  0.5,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.5625,\n",
              "  0.625,\n",
              "  0.5,\n",
              "  0.5,\n",
              "  0.5],\n",
              " 'val_loss': [0.8364540934562683,\n",
              "  0.9376440048217773,\n",
              "  1.1853907108306885,\n",
              "  1.2927249670028687,\n",
              "  1.0376622676849365,\n",
              "  0.8378043174743652,\n",
              "  0.8974912166595459,\n",
              "  1.0456453561782837,\n",
              "  1.289621353149414,\n",
              "  1.4594392776489258,\n",
              "  1.4582953453063965,\n",
              "  1.316983699798584,\n",
              "  1.1603631973266602,\n",
              "  1.0619926452636719,\n",
              "  1.0485751628875732,\n",
              "  1.0487823486328125,\n",
              "  1.0491275787353516,\n",
              "  1.1240381002426147,\n",
              "  1.1809381246566772,\n",
              "  1.22555673122406]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 299
        }
      ]
    }
  ]
}
